{
    "Transformer": {
        "num_layers": 4,
        "num_heads": 8,
        "official": false,
        "dropout": 0.1, 
        "attention_dropout": 0.1
    }

}
